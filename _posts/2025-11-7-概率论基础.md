---
title: 第一章 概率论基础
date: 2025-11-7 10:00:00 +0800
categories: [数学原理, 随机过程]
tags: [概率论, 试验, 样本空间, sigma-代数]
math: true
description: 概率论基础是随机过程的基础，包括试验、样本空间与 sigma-代数等概念。
---

## 一、概率论基础

### 1. 试验、样本空间与 $\sigma$ -代数

- 随机试验：需满足可重复性、结果明确性、不确定性

  > [!NOTE]
  >
  > 可重复性：在**相同条件**下可重复进行
  >
  > 结果明确性：所有可能的结果在**试验前已知**
  >
  > 不确定性：具体到将要进行的试验，试验前结果**未知**
<!-- 以上的特性在**一次随机试验**就可以体现 -->
  > [!CAUTION]
  >
  > 以上的特性在**一次随机试验**就可以体现

- 样本空间（ $\Omega$ ）

  - 定义：随机试验所有可能结果（样本点 $\omega_i$ ）的集合

    > [!NOTE]
    >
    > 此处的随机试验可以是**单次试验组合**成的**复合试验**，例如“连续两次掷骰子”为一次复合试验，可能的结果有 36 种，所以该样本空间为 $\Omega=\{\omega_i\|i=1,2,3,…,36\}$
    >
    > 注意：样本空间中样本点的数量和随机试验的进行次数无关

  - 基本事件：仅包含一个样本点的事件，记为 $\{\omega_i\}$

    > [!Caution]
    >
    > **事件不等于样本空间**，样本空间（$\Omega$）是 “所有可能结果的全集”，而事件是 “样本空间的任意子集”，简单说就是：**样本空间是特殊的事件（必然事件），但事件的范围比样本空间更宽泛**。
    >
    > 我们可以认为事件和样本空间都是对一个试验可能的结果的描述，样本空间是所有可能的结果，而事件是将部分可能的结果取出来。
    >
    > 举例：投一次骰子，可知样本空间$\Omega=\{1,2,3,4,5,6\}$，两种事件（描述）$A$ 和 $B$，对于 $A$ 我们可以描述为“投一次骰子，投出了 1”，那么 $A=\{1\}$；对于 $B$ 我们描述为“ 投一次骰子，投出了 1 或 3 或 6”，那么 $B=\{1,3,6\}$。由此我们可以推断 $C=\{1,2,3,4,5,6\}$ 描述为“投一次骰子，投出 1~6 中的一个数字”，当然了这是必然的，所以**必然事件就是样本空间本身，不可能事件就是一个空集**。
    <!-- 以上的性质在**一次随机试验**就可以体现 -->
    > [!NOTE]
    >
    > 所以，基本事件应该是一个样本空间的子集，并且它只包含一个可能的结果（样本点 $\omega_i$ ），注意 $i$ 是对于样本空间来说的。

  - 性质：随试验不同而变化，可能含有限个、可列个样本点
<!-- 以上的性质在**一次随机试验**就可以体现 -->
- $\sigma$ - 代数（ $\mathcal F$ ，事件集合）

  - 定义：满足以下 **3 个条件**的事件集合

    1. 样本空间属于 $\sigma$ - 代数：$(\Omega \in \mathcal F)$

    2. 补集封闭：若$(A \in \mathcal F)$，则$(\bar{A} \in \mathcal F)$

    3. 可列并封闭：对任意$(A_{i} \in \mathcal F),(i=1,2,\cdots)$，均有$(\cup_{i=1}^{\infty} A_{i} \in \mathcal F)$ ​

       > [!NOTE]
       >
       > $\mathcal F$ 的元素是**事件** $A$ ，以下是对 3 个条件的理解：
       >
       > 1. 由上面的内容我们可知，**样本空间就是一个必然事件**，根据 $\sigma$ - 代数的定义，所以必然事件可以作为事件集合的一个元素，换个写法为： $\mathcal F =\{\Omega,...\}$
       > 2. $\mathcal F$ 中所含的所有事件及其的互补事件都得在这个事件集合中，注意 $A_i \cup \bar{A_i}=\Omega,\mathcal F =\{\Omega,A_i,\bar{A_i},...\}$
       > 3. 对于任意个事件的并集也在这个事件集合中，即 $A_i \cup \bar{A_i}=\Omega,\mathcal F =\{\Omega,A_i,\bar{A_i},\cup_{i=1}^{\infty} A_{i},...\}$
       >
       > 举例：
       >
       > 1. 假设 $\Omega=\{\varnothing\}$ ，很明显复合 3 个条件。

  - 推论：

    1. 由 条件 3 可以推导出：如果两个事件 $A、B \in \mathcal F$，则 $AB \in \mathcal F$​

       > [!NOTE]
       >
       > 我们可以认为此时有两个个事件 $A、B$ 属于这个事件集合，那么可以将他们的子集 $AB,A-AB,B,B-AB$ 都添加到这个事件集合中，即 $A=AB+(A-AB)，B=AB+(B-AB)$ ，则 $AB \in \mathcal F$

    2. 由条件 2 可以推出： $\bar{B} \in \mathcal F$ ；再由推论 1 可以推导出： $A、\bar{B} \in \mathcal F$，则 $A \bar{B} \in \mathcal F$ ，即总结为无限/有限交/并，也属于 $\sigma$ - 代数

### 2. 概率与概率空间

- 概率（$P$）

  - 定义：定义在 $\sigma - 代数 \mathcal F$ 上的集函数，满足 3 条公理：

    > [!NOTE]
    >
    > 根据定义我们可以知道，**概率（ $P$ ）是**一个以事件为自变量（即定义域为 $\sigma - 代数 \mathcal F$ ）的**函数**，其值我们可以表示为 $p$ ，即 $p_i=P(A_i),A_i \in \mathcal F$ ；注意**概率是函数，即一种映射**

    1. 非负性： $P(A) \geqq 0$ ，对任意 $A \in \mathcal F$ 成立

    2. 正规性： $P(\Omega)=1$

       > [!NOTE]
       >
       > 因为 $\Omega$ 是样本空间，即也代表着必然事件；显然，必然事件的概率为 1

    3. 可列可加性： 对任意互斥的事件 $A_i \in \mathcal F , P(\cup_{i=1}^{\infty}A_i)={\sum}_{i=1}^{\infty}P(A_i)$

- 概率空间（ $\Omega,\mathcal F,P$ ）：这样括号表示的形式就是**概率空间**，由样本空间（ $\Omega$ ）， $\sigma - 代数 (\mathcal F)$ ，概率（ $P$ ）三要素构成

  > [!NOTE]
  >
  > 为什么不是别的概念来构成概率空间？
  >
  > 1. $\Omega$ 是 “基础”：确定讨论的所有可能结果；
  > 2. $\mathcal F$ 基于 $\Omega$：从 $\Omega$ 的子集中筛选出合法事件；
  > 3. $P$ 作用于$\mathcal F$：给合法事件赋予概率值。
  >
  > 缺少任何一个，都无法构成完整的 “随机现象数学模型”—— 比如只有 $\Omega$ 和$\mathcal F$，只能描述 “有哪些事件”，却不知道 “事件发生的可能性”(样本空间-->事件-->$\sigma$ - 代数，却没计算事件的概率)；只有 $\Omega$ 和 $P$ ，会因 “事件不合法” 导致概率计算矛盾（样本空间-->每个样本点的概率，却不能给出事件的概率）。

### 3. 随机变量与分布

- 随机变量（ $X(\omega)$ ）：

  - 定义：随机变量（ $X(\omega)$ ）是定义在 $\Omega$ 上的单值实值函数

  > [!NOTE]
  >
  > 因为定义域 $\Omega$ 是样本空间，所以随机变量（ $X(\omega)$ ）的自变量是样本点（ $\omega$ ）

  - 示例：抛硬币模型$(\Omega=\{\omega_1,\omega_2\}，X(\omega_1)=0，X(\omega_2)=1)$

- 事件：若对于任意一实数 $x \in R$ ，都有集合 $\{\omega \| X(\omega) \leq x\} \in \mathcal F$ ，那么 $\{\omega \| X(\omega) \leq x\} = A =事件$

  > [!NOTE]
  >
  > 也就是说，事件是一个**样本点（ $\omega$ ）的集合** ，和我们之前理解的——**事件是样本空间的子集**是一致的

> [!IMPORTANT]
>
> 至此，我们做一个总结，以上所有概念如图：
>
> ```mermaid
> graph TD
>     A[样本点<br/><span style='font-size:12px;color:#666'>定义：随机试验的基本结果（最小单位）</span>]
>
>     A -->|构成（全集）| B[样本空间<br/><span style='font-size:12px;color:#666'>定义：所有样本点的集合，随机变量的定义域</span>]
>     B -->|组合（子集）| C[事件<br/><span style='font-size:12px;color:#666'>定义：样本空间的子集，对样本点的分类结果，sigmma-代数的元素</span>]
>
>     C -->|函数映射（量化可能性）| D[概率<br/><span style='font-size:12px;color:#666'>定义：关于“事件”的函数，输出0到1的数值</span>]
>
>     A -->|函数映射（转化为实数）| E[随机变量<br/><span style='font-size:12px;color:#666'>定义：关于“样本点”的函数，输出实数</span>]
>     B -->|作为（定义域）| E
>
>     E -->|对应（取值范围→样本点集合）| C
>
>     F[sigmma-代数 <br/><span style='font-size:12px;color:#666'>定义：以合法事件为元素的集合族</span>]
>
>     C -->|作为（元素）| F
> ```

- 概率分布（ $F(x)$ ）

  - 定义：概率分布是关于随机变量的函数，其代表的含义是概率 $P$，用于表征 $P(X \leq x)$

    > [!NOTE]
    >
    > $$
    > \text{随机变量取值条件 } X \leq x \xrightarrow{\text{转化为样本点集合}} \text{事件 } A = \{\omega \mid X(\omega) \leq x\} \xrightarrow{\text{概率作用于事件}}  P(A) = P\left(\{\omega \mid X(\omega) \leq x\}\right) \\
    > \xrightarrow{\text{简化书写}} P(X \leq x) \xrightarrow{\text{概率分布定义}} F(x) = P(X \leq x)
    > $$

  - 特征性质：

    1. 非降性：若 $x_1 < x_2$，则$F(x_1) \leq F(x_2)$
    2. 右连续性：$F(x^+)=F(x)$
    3. 极限条件：$F(-\infty)=0，F(+\infty)=1$

  - 逆命题：满足上述 3 条性质的实函数，必为某随机变量的分布函数

- 离散型随机变量

  - 定义：取值至多为可列个

    > [!NOTE]
    >
    > 意思是， $X(\omega)$ 的结果是一个离散的相空间 $S=\{x_1,x_2,...\}$

  - 分布列： $p_k=P(X=x_k),(k=1,2,...)$ ，满足 $p_k \geq 0$ ，且 $\sum_k p_k = 1$

  - 分布函数：$F(x) = \sum_{x_k \leq x} p_k$ ，为跳跃函数

- 连续型随机变量

  - 定义：取值充满某一区间，分布函数可标识为 $F(x)=\int_{-\infty}^{x} f(t)dt$ （$f(t)$ 为非负函数）
  - 概率函数（$f(t)$）：满足 3 条性质
    1. 非负性：$f(t) \geq 0$
    2. 规范性：$\int_{-\infty}^{+\infty} f(t)dt=1$
    3. 导数关系：$f(t)=\frac{d}{dt}F(t)$（$F (t) $可导处）

  > [!NOTE]
  >
  > 对比离散型随机变量和连续型随机变量的**规范性条件**，我们会发现：离散型的 $P(X=x_k)$ 对应连续性的 $f(t)$ ，但是注意的是连续性随机变量并没有某个点的概率的概念

- 多维随机变量（以 n 维 $X=(X_1,\cdots,X_n)^T$为例）

  - 联合分布函数：$F_X(x_1,\cdots,x_n)=P(X_1 \leq x_1,\cdots,X_n \leq x_n)(\forall x_1,\cdots,x_n \in \mathbb{R})$
  - 性质：对每个变量非降、右连续；单变量趋于$-\infty$时极限为 0，全变量趋于$+\infty$时极限为 1

- 随机变量的函数分布

  - 基本公式：设 $Y=g(X)$ ( $g$ 为可预测函数)，则 $F_Y=P(Y \leq y)=P(g(X) \leq y)$

  - 单调函数特例：

  - 若 g 为严格单调函数，且$g^{-1}(y)$连续可导，则 Y 的概率密度为
    $$
    f_Y(y)= \begin{cases}f_X(g^{-1}(y))\left\|(g^{-1}(y))'\right\|, & y \in (\alpha,\beta) \\ 0, & y \notin (\alpha,\beta)\end{cases}
    $$

> [!NOTE]
>
> 概率分布函数是一个关于概率 $P$ 的函数，而随机变量的分布函数是一个关于随机变量 $X$ 的函数
>
> 再次回顾：**概率** $P$ 是关于**事件** $A$ 的函数，而**随机变量** $X$ 是关于**样本点** $\omega$ 的函数，**事件是以样本点为元素的集合**，**所以通过对随机变量的不等式可以筛选符合该不等式的样本点，这些样本点组合在一起就是事件啦**

### 4. 条件概率与条件分布

- 条件概率$P (A\|B)$

  - 定义：设概率空间（ $\Omega,\mathcal F,P$ ），从 $\sigma$ -代数中任选两个事件 $A、B$ ，条件概率就写为： $P (A\|B) = \frac{P(AB)}{P(B)}$

    > [!NOTE]
    >
    > 很好理解：从描述上来说，条件概率代表的是（（在事件 B 发生的基础上）事件$A$发生）的概率，也就是说条件概率的**有效样本空间**已经从**样本空间**转变为事件$B$（样本空间就是必然事件），同时事件$A$在事件$B$中所占的位置就是$AB$，那么此时，写为另一种形式就是：在概率空间（ $B,\mathcal F^{'},P$ ）中, 求 $P(A)$

  - 相关公式

    1. 乘法公式：$P(AB)=P(B) P(A\|B)=P(A)P(B\|A)$

       > [!NOTE]
       >
       > 注意：此时的概率空间为（ $\Omega,\mathcal F,P$ ）

    2. 全概率公式：设$A_i$满足$A_i \cap A_j=\emptyset$（$i \neq j$）、$\cup_i A_i=\Omega$、$P(A_i)>0$，则对任意$B \in F$，$P(B)=\sum_i P(A_i)P(B\|A_i)$ ​

       > [!NOTE]
       >
       > $P(B)=P(B(A_1+A_2+...+A_i))=P(B\Omega)$ ，根据乘法公式：$P(B\Omega)=P(\Omega)P(B\|\Omega)$ ，
       >
       > 写为加法的形式就是: $\sum_i P(A_i)P(B\|A_i)$

    3. 贝叶斯公式：在全概率公式条件下，$P(A_k\|B)=\frac{P(A_k)P(B\|A_k)}{\sum_i P(A_i)P(B\|A_i)}$（$k=1,2,\cdots$）

       > [!NOTE]
       >
       > 根据条件概率定义：$P(A_k\|B)=\frac{P(A_kB)}{P(B)}$
       >
       > 根据乘法公式：$P(A_k\|B)=\frac{P(B) P(A_k\|B)}{P(B)}=\frac{P(A_k) P(B\|A_k)}{P(B)}$
       >
       > 根据全概率公式：$P(A_k\|B)=\frac{P(A_k) P(B\|A_k)}{\sum_k P(A_k)P(B\|A_k)}$
      <!-- 以上的公式在**一次随机试验**就可以体现 -->
       > [!IMPORTANT]
       >
       > 全概率公式（死脑筋穷举）：
       >
       > - 举例：像感冒发生的概率 $P(B)$ ，其实受很多因素影响，如天气、体质、是否可以预防……；很显然，计算这个概率要考虑很多东西，但是我们可以将这些因素进行“控制变量法”，将这些因素分割为互斥的事件，统计或者计算这些因素发生的概率 $P(A_i)$ 和在每个因素的影响下感冒的发生概率 $P(B\|A_i)$
       > - 好处：将一个复杂的因果概率转换为可以进行实验，进行统计计算得到的实验室数据，根据实验数据进行计算
       > - 缺陷：
       >   - 不一定能穷举影响结果$P(B)$的所有因素
       >   - 这些因素不一定都能相互独立，例如是否有意识预防会受今天是否看天气预报的影响
       >
       > 贝叶斯公式（事后诸葛亮）：
       >
       > - 举例：常用于医学诊断，在疫情期间，假设某人感到发烧，那么就可以得到一个猜测 $P(A_k)$ 患病了，这个应该做核算检测，但是核算检测试纸会有概率出错，所以核算检测正确的概率为 $P(B)$ ，测完还能就能获得 $P(B\|A_k)$ ，这个时候我们就能确定这个人是不是真的阳了 $P(A_k\|B)$ ，依旧是对猜测的表述，只是更加精确了，因为样本空间缩小了
       > - 好处：当我们有一个猜测，并且可以有一个去验证的实验，那么我们就可以使用贝叶斯公式去修正我们的猜测
       > - 缺陷：
       >   - 因为继承了全概率公式，所以也继承其缺点，即如果猜测一开始不能穷举，那么就完了
       >   - 很依赖一开始猜测的准确性，如果一开始猜的准，那结果会更好，如果猜的不好，容易有很大的误差

- 条件分布

  - 离散型（$(X,Y)^T$）为离散型随机变量，$P(X=x)>0$ ：

    1. 条件分布列：$P_{Y∣X}(y∣x)=P(Y=y∣X=x)=\frac {P(X=x,Y=y)}{P(X=x)}$

       > [!NOTE]
       >
       > 随机变量是关于样本点的函数，事件的元素是样本点，对随机变量的数值进行限制就是对事件进行筛选，获取有效事件
       >
       > 所以离散型随机变量的条件概率正确写法为 $P(Y=y∣X=x)$ ，可以简写为 $P_{Y∣X}(y∣x)$ ，严忌写法 $P_{Y\|X}$

    2. 条件分布函数：$F_{Y\|X}(y\|x)=P(Y \leq y\|X=x)=\frac{P(X=x,Y \leq y)}{P(X=x)}$

       > [!NOTE]
       >
       > 注意：条件分布函数特指 $X=x$ 的情况下 $Y \leq y$ 的概率

  - 连续型（$(X,Y)^T$为连续随机变量，$f_X(x)>0$）

    1. 条件分布函数：$F_{Y\|X}(y\|x)=\frac{\int_{-\infty}^y f(x,\tilde{y})d\tilde{y}}{f_X(x)}$
    2. 条件概率密度：$f_{Y\|X}(y\|x)=\frac{\partial}{\partial y}F_{Y\|X}(y\|x)=\frac{f(x,y)}{f_X(x)}$

### 5. 独立性

- 事件的独立性
  - 定义：若 $A、B \in \mathcal F 且 P(AB)=P(A)P(B)$ ，则称 $A$ 与 $B$ 相互独立
  - 性质
    1. 若$P(B)=0$，则 B 与任意事件独立
    2. 若$P(B)>0$，则 A 与 B 独立等价于$P(A\|B)=P(A)$（B 的发生不影响 A 的统计规律）
  - 充要条件
    1. 离散型：$P(X_1=x_1,\cdots,X_n=x_n)=\prod_{k=1}^n P(X_k=x_k)$
    2. 连续型：$f_X(x_1,\cdots,x_n)=\prod_{k=1}^n f_{X_k}(x_k)$
  - 性质
    1. 相互独立的随机变量，其任意子集也相互独立
    2. 若$X_1,\cdots,X_n$独立，$f_1,\cdots,f_n$为可测函数，则$f_1(X_1),\cdots,f_n(X_n)$独立
    3. 事件$A_1,\cdots,A_n$独立，当且仅当其示性函数$I_{A_1},\cdots,I_{A_n}$独立

### 6. 数字特征

- 数学期望（$E (X)$）

  - 定义：$E(X)=\int_{-\infty}^{+\infty} xdF_X(x)$，具体形式为

    - 离散型：$E(X)=\sum_{k=1}^{\infty} x_k p_k$（$p_k=P(X=x_k)$）
    - 连续型：$E(X)=\int_{-\infty}^{+\infty} x f(x)dx$

  - 函数期望：$E(g(X))=\int_{-\infty}^{+\infty} g(x)dF_X(x)$；多维情形：$E(g(X_1,\cdots,X_n))=\int_{-\infty}^{+\infty}\cdots\int_{-\infty}^{+\infty} g(x_1,\cdots,x_n)dF_X(x_1,\cdots,x_n)$

    > [!NOTE]
    >
    > 函数 $g(X)$ 的本质还是一个关于样本点的函数，当其取到某个值的时候依旧是对事件的筛选，同时也可以看作是随机变量$X$取到某个值$x$，所以 $g(X=x)=g(x)$；其概率则为$P(g(X=x))$，其实还是概率$P(X=x)$，对应连续型为$dF_X(x)$

  - 性质

    1. 常数期望：$E(C)=C$（C 为常数）
    2. 线性性：$E(aX+bY)=aE(X)+bE(Y)$（a,b 为常数）
    3. 独立性性质：若 X 与 Y 独立，则$E(XY)=E(X)E(Y)$
    4. 非负性：若$X \geq 0$，则$E(X) \geq 0$
    5. 单调性：若$X \geq Y$，则$E(X) \geq E(Y)$
    6. 绝对值不等式：$\|EX\| \leq E\|X\|$
    7. 柯西 - 施瓦茨不等式：$(E\|XY\|)^2 \leq E(X^2)E(Y^2)$

  - 方差（$D (X)=Var (X)=\sigma^2(X)$）

    - 定义：$D(X)=E((X-E(X))^2)=\int_{-\infty}^{+\infty} (x-E(X))^2 dF_X(x)$ ，也记为$\sigma^2(X)$

      > [!NOTE]
      >
      > 方差表征的是随机变量取值与中心的偏离距离的平方的期望，同理，其概率也下放到随机变量取到某个值

    - 核心公式：$D(X)=E(X^2)-(E(X))^2$

      $$
      \begin{align}
      D(X)&=E((X-E(X))^2) \\
      &=E(X^2+E^2(X)-2XE(X)) \\
      &=E(X^2)+E(E^2(X))-E(2XE(X)) \\
      &=E(X^2)+E^2(X)-2E(X)E(E(X)) \\
      &=E(X^2)-E^2(X)
      \end{align}
      $$

      > [!NOTE]
      >
      > 如果忽略平方，则为：$E(\|X\|)-E(X)$ ，解释为正向随机变量的期望和中心（认为期望代表中心）的距离，和最初的表征含义一样

    - 性质

      1. 常数方差：$D(C)=0$（C 为常数）

      2. 独立性性质：若 X 与 Y 独立，则$D(X \pm Y)=D(X)+D(Y)$

         > [!NOTE]
         >
         > 注意此处是 X 与 Y 是独立的

      3. 线性变换：$D(aX+b)=a^2 D(X)$（a,b 为常数）

         > [!NOTE]
         >
         > 很好理解，因为$D(X)=E(X^2)-(E(X))^2$ ，所以不管随机变量的系数是多少都会被平方

      4. 最小性：对任意常数 C，$D(X) {\leq} E(X-C)^2$

         > [!NOTE]
         >
         > $$
         > \begin{align}
         > E((X-C)^2)-D(X)&=E(X^2-2CX+C^2)-D(X)\\
         > &=E(X^2)-2CE(X)+C^2-E(X^2)+E^2(X)\\
         > &=E^2(X)-2CE(X)+C^2 \\
         > &=(E(X)-C)^2 \geq 0
         > \end{align}
         > $$

    - 矩：k 阶原点矩（$E(X^k)$，期望$E(X^1)$为 1 阶原点矩）、k 阶绝对矩（$E\|X\|^k$）、k 阶中心矩（$E((X-E(X))^2)$，方差为 2 阶中心矩）

      > [!NOTE]
      >
      > 简单来说原点矩就是将被求期望的随机变量开$k$次幂，例如在方差中，可以认为$Y=X-E(X)$ ，但是其含义我们一直说过表征数值到中心的距离，所以进一步强化为中心矩。顾名思义，绝对矩同理是一样的

    - 多维数字特征

      - 协方差：$Cov(X_i,X_j)=E(X_i-E(X_i))(X_j-E(X_j))=E(X_iX_j)-E(X_i)E(X_j)$
      - 协方差矩阵：$(Cov(X_i,X_j))_{n \times n}$，为对称、非负定矩阵
      - 相关系数：$\rho_{X_iX_j}=\frac{Cov(X_i,X_j)}{\sqrt{D(X_i)D(X_j)}}$，性质：$\|\rho\| \leq 1$；$\|\rho\|=1$等价于 X 与 Y 线性相关；$\rho=0$时称 X 与 Y 不相关（独立必不相关，反之未必）

### 7. 特征函数

- 定义：设随机变量 X 的分布函数为 $F(x)$，则 $\psi(u)=E(e^{iuX})=\int_{-\infty}^{+\infty} e^{iux}dF(x)$（u 为实数，i 为虚数单位，$e^{iux}=cosux+i sinux$ ）

  - 离散型：$\psi_X(u)=\sum_{k=1}^{\infty} e^{iux_k}P(X=x_k)$
  - 连续型：$\psi_X(u)=\int_{-\infty}^{+\infty} e^{iux}f(x)dx$

    > [!NOTE]
    >
    > 和分布函数相比，就是将$x$替换为了$e^{iux}$，并且函数的自变量是$u$
    >
    > 从期望的角度看，特征函数中随机变量是$Y=e^{iuX}$是一个关于$X$的函数，符合其随机变量的概率和$X$的概率相同的结论。其形式符合期望的定义，所以$\psi(u)=E^Y=E(e^{iuX})$

- 性质

  1. 存在性：任何随机变量的特征函数都存在（因$\|e^{iux}\| \leq 1$，积分 / 求和收敛）
  2. 有界性：$\|\psi(u)\| \leq \psi(0)=1$
  3. 共轭性：$\psi(-u)=\overline{\psi(u)}$（$\overline{\psi(u)}$为$\psi(u)$的共轭）
  4. 线性变换：若$Y=aX+b$，则$\psi_Y(u)=e^{ibu}\psi_X(au)$

     > [!NOTE]
     >
     > 以离散型为例，$P(Y=y)$实际上就是$P(X=x)$，此处我们在之前讲过，对随机变量$Y$的筛选在变相地决定$X$的取值，即对$X$的筛选。
     >
     > 关于$e^{iuy}=e^{iu(ax+b)}=e^{iaux}e^{ibu}$，则获得系数$e^{ibu}$

  5. 矩的关系：若 X 的 k 阶矩存在，则$\psi_X(u)$k 阶可导，且$\psi_X^{(k)}(0)=i^k E(X^k)$

     > [!NOTE]
     >
     > 若 X 的 k 阶矩存在，则 X 的期望为$E(X)$，且$\psi_X(u)$一阶可导，则求导：
     >
     > $$
     > \psi_X'(u) = \frac{d}{du} \int_{-\infty}^{+\infty} e^{iux} f(x) dx = \int_{-\infty}^{+\infty} \frac{\partial}{\partial u} \left( e^{iux} f(x) \right) dx = \int_{-\infty}^{+\infty} ix e^{iux} f(x) dx
     > $$
     >
     > 在求导结果中，我们可以认为新的随机变量$Z$的取值$z= ix e^{iux}$，是一个关于$x$的函数，所以对$Z$的筛选就是对$X$的筛选；因为此处有复数域，所以当$u=0$时，我们认为这是对$iX$的筛选，则期望为$E(iX)=iE(X)$；
     >
     > 同理对特征函数继续求导，因为$e^{ix}$的存在，只会累积次数

  6. 连续性：$\psi_X(u)$在$\mathbb{R}$上一致连续
  7. 逆变换：若$\int_{-\infty}^{+\infty}\|\psi(u)\|du<\infty$，则概率密度$f(x)=\frac{1}{2\pi}\int_{-\infty}^{+\infty} e^{-iux}\psi(u)du$（与特征函数构成傅里叶变换对）

- 多维特征函数：设$X=(X_1,\cdots,X_n)^T$，其特征函数为$\psi_X(u_1,\cdots,u_n)=E(e^{i(u_1X_1+\cdots+u_nX_n)})$

  > [!NOTE]
  >
  > 上面我们证明了$\psi(u)=E(e^{iuX})$

  - 独立性充要条件：$X_1,\cdots,X_n$相互独立等价于$\psi_X(u_1,\cdots,u_n)=\prod_{k=1}^n \psi_{X_k}(u_k)$
  - 和的特征函数：若$X_1,\cdots,X_n$独立，$Y=\sum_{k=1}^n X_k$，则$\psi_Y(u)=\prod_{k=1}^n \psi_{X_k}(u)$

    > [!NOTE]
    >
    > 注意独立条件即可

### 8. 条件期望

- 定义：设$(X,Y)^T$为二维随机变量，$F_{Y\|X}(y\|x)$为$X=x$条件下 Y 的条件分布函数，则$E(Y\|X=x)=\int_{-\infty}^{+\infty} y dF_{Y\|X}(y\|x)$

  > [!NOTE]
  >
  > 注意条件分布函数的定义:$F_{Y\|X}(y\|x)=P(Y \leq y\|X=x)$

  - 离散型：$E(Y\|X=x)=\sum_y y P(Y=y\|X=x)$
  - 连续型：$E(Y\|X=x)=\int_{-\infty}^{+\infty} y f_{Y\|X}(y\|x)dy$

- 全期望公式：$EY=E(E(Y\|X))$，具体形式为

  - 离散型：$EY=\sum_x E(Y\|X=x)P(X=x)$
  - 连续型：$EY=\int_{-\infty}^{+\infty} E(Y\|X=x)f_X(x)dx$

    > [!NOTE]
    >
    > 条件期望$E(Y\|X=x)$是关于随机变量$Y$的期望，该期望的值是在情况$X=x$的情况下取得的，所以该条件期望也可以认为是一个关于$X$的函数，则当$x$不是一个确定值时，$E(Y\|X=x)$就是一个随机变量，写为$E(Y\|X)$。
    >
    > 既然是随机变量，那么我们也可以对其求期望，该期望公式中的概率$P(E(Y\|X=x_k))=P(X=x_k)$，连续型中为$f_X(x)$，随机变量都为$E(Y\|X=x_k)$
